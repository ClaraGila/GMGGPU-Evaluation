9.078980661825146e-07
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------



      ##########################################################
      #                                                        #
      #                       WARNING!!!                       #
      #                                                        #
      #   This code was compiled with a debugging option.      #
      #   To get timing results run ./configure                #
      #   using --with-debugging=no, the performance will      #
      #   be generally two or three times faster.              #
      #                                                        #
      ##########################################################


/home/clara/PycharmProjects/untitled/diff_meshes.py on a arch-linux2-c-debug named clara with 1 processor, by clara Mon May 18 11:17:30 2020
Using Petsc Development GIT revision: v3.4.2-29593-g905158c6f9  GIT Date: 2020-04-24 15:50:17 +0100

                         Max       Max/Min     Avg       Total 
Time (sec):           1.646e+01     1.000   1.646e+01
Objects:              9.950e+02     1.000   9.950e+02
Flop:                 1.340e+07     1.000   1.340e+07  1.340e+07
Flop/sec:             8.139e+05     1.000   8.139e+05  8.139e+05
Memory:               3.013e+06     1.000   3.013e+06  3.013e+06
MPI Messages:         0.000e+00     0.000   0.000e+00  0.000e+00
MPI Message Lengths:  0.000e+00     0.000   0.000e+00  0.000e+00
MPI Reductions:       0.000e+00     0.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total 
 0:      Main Stage: 1.0753e+00   6.5%  0.0000e+00   0.0%  0.000e+00   0.0%  0.000e+00        0.0%  0.000e+00   0.0% 
 1:          warmup: 1.1406e+01  69.3%  6.6997e+06  50.0%  0.000e+00   0.0%  0.000e+00        0.0%  0.000e+00   0.0% 
 2:       benchmark: 3.9809e+00  24.2%  6.6997e+06  50.0%  0.000e+00   0.0%  0.000e+00        0.0%  0.000e+00   0.0% 

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
   GPU Mflop/s: 10e-6 * (sum of flop on GPU over all processors)/(max GPU time over all processors)
   CpuToGpu Count: total number of CPU to GPU copies per processor
   CpuToGpu Size (Mbytes): 10e-6 * (total size of CPU to GPU copies per processor)
   GpuToCpu Count: total number of GPU to CPU copies per processor
   GpuToCpu Size (Mbytes): 10e-6 * (total size of GPU to CPU copies per processor)
   GPU %F: percent flops on GPU in this event
------------------------------------------------------------------------------------------------------------------------


      ##########################################################
      #                                                        #
      #                       WARNING!!!                       #
      #                                                        #
      #   This code was compiled with a debugging option.      #
      #   To get timing results run ./configure                #
      #   using --with-debugging=no, the performance will      #
      #   be generally two or three times faster.              #
      #                                                        #
      ##########################################################


Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total   GPU    - CpuToGpu -   - GpuToCpu - GPU
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s Mflop/s Count   Size   Count   Size  %F
---------------------------------------------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

PetscBarrier           4 1.0 5.5258e-02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   5  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
SFSetGraph             2 1.0 2.6840e-06 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
VecSet                18 1.0 2.5561e-05 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
VecCUDACopyTo          2 1.0 3.7702e-05 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      2 7.94e-02    0 0.00e+00  0
VecCUDACopyFrom        4 1.0 7.0193e-05 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    4 1.59e-01  0
DMPlexCrFrCeLi         2 1.0 4.5558e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
DMPlexCrFrCeLiCo       2 1.0 1.1472e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
DMPlexInterp           2 1.0 3.3602e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
DMPlexStratify         8 1.0 4.5437e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
DMPlexSymmetrize       8 1.0 3.9398e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
CreateMesh            24 1.0 5.3580e-02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   5  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
Mesh: reorder          6 1.0 6.8530e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   1  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
Mesh: numbering        6 1.0 2.9612e-02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   3  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
CreateFunctionSpace       8 1.0 4.4139e-02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   4  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ParLoopExecute         3 1.0 5.4236e-02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   5  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ParLoop_wrap_expression_kernel       2 1.0 6.4410e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ParLoop_wrap_expression       2 1.0 2.2731e-05 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
AssembleExpression       1 1.0 9.3556e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   1  0  0  0  0     0       0      0 0.00e+00    1 5.25e-02  0
ParLoop_wrap_form_cell_integral_otherwise       2 1.0 4.3472e-05 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ParLoopRednBegin       1 1.0 2.8172e-05 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ParLoopRednEnd         1 1.0 3.2702e-05 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0

--- Event Stage 1: warmup

VecMDot               95 1.0 8.1192e-03 1.0 1.77e+06 1.0 0.0e+00 0.0e+00 0.0e+00  0 13  0  0  0   0 26  0  0  0   217    1407      0 0.00e+00    0 0.00e+00 100
VecNorm              101 1.0 7.2111e-03 1.0 2.63e+05 1.0 0.0e+00 0.0e+00 0.0e+00  0  2  0  0  0   0  4  0  0  0    36      37      0 0.00e+00    0 0.00e+00 100
VecScale             100 1.0 8.7980e-04 1.0 1.25e+05 1.0 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  2  0  0  0   142     163      0 0.00e+00    0 0.00e+00 100
VecCopy              373 1.0 4.8823e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
VecSet               170 1.0 2.9050e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
VecAXPY                9 1.0 9.3823e-05 1.0 5.21e+04 1.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  1  0  0  0   555     685      0 0.00e+00    0 0.00e+00 100
VecAYPX               20 1.0 2.7424e-04 1.0 1.36e+05 1.0 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  2  0  0  0   494     563      0 0.00e+00    0 0.00e+00 100
VecAXPBYCZ             6 1.0 1.6077e-04 1.0 1.98e+05 1.0 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  3  0  0  0  1234    1447      0 0.00e+00    0 0.00e+00 100
VecMAXPY             100 1.0 9.8739e-03 1.0 4.00e+06 1.0 0.0e+00 0.0e+00 0.0e+00  0 30  0  0  0   0 60  0  0  0   405     465      0 0.00e+00    0 0.00e+00 100
VecPointwiseMult     112 1.0 1.7932e-03 1.0 1.65e+05 1.0 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  2  0  0  0    92     114      5 1.35e-01    0 0.00e+00 100
VecNormalize         100 1.0 8.1972e-03 1.0 3.75e+05 1.0 0.0e+00 0.0e+00 0.0e+00  0  3  0  0  0   0  6  0  0  0    46      48      0 0.00e+00    0 0.00e+00 100
VecCUDACopyTo         35 1.0 6.9976e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0     35 8.27e-01    0 0.00e+00  0
VecCUDACopyFrom      149 1.0 1.5866e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00  149 3.17e+00  0
MatMult              111 1.0 2.6786e+00 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00 16  0  0  0  0  23  0  0  0  0     0       0      0 0.00e+00    3 6.95e-02  0
MatMultAdd             3 1.0 1.2463e-03 1.0 1.98e+04 1.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0    16     323      0 0.00e+00    0 0.00e+00 100
MatMultTranspose       9 1.0 5.2383e+00 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00 32  0  0  0  0  46  0  0  0  0     0       0      3 1.22e-01    6 2.93e-01  0
MatResidual            3 1.0 1.0193e-03 1.0 1.98e+04 1.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0    19     142      0 0.00e+00    0 0.00e+00 100
MatAssemblyBegin       6 1.0 1.1640e-05 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
MatAssemblyEnd         6 1.0 1.0925e-05 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
PCSetUp                1 1.0 5.9633e+00 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00 36  0  0  0  0  52  0  0  0  0     0       0     21 3.33e-01   65 1.26e+00  0
PCApply                1 1.0 4.9618e+00 1.0 6.67e+06 1.0 0.0e+00 0.0e+00 0.0e+00 30 50  0  0  0  44100  0  0  0     1     275      8 2.05e-01   74 1.44e+00 100
KSPSetUp               6 1.0 2.1037e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00   23 6.50e-01  0
KSPSolve               1 1.0 1.0925e+01 1.0 6.69e+06 1.0 0.0e+00 0.0e+00 0.0e+00 66 50  0  0  0  96100  0  0  0     1     260     29 5.38e-01  139 2.70e+00 100
KSPGMRESOrthog        95 1.0 1.9286e-02 1.0 5.30e+06 1.0 0.0e+00 0.0e+00 0.0e+00  0 40  0  0  0   0 79  0  0  0   275     577      0 0.00e+00    0 0.00e+00 100
SNESSolve              1 1.0 1.1106e+01 1.0 6.70e+06 1.0 0.0e+00 0.0e+00 0.0e+00 67 50  0  0  0  97100  0  0  0     1     260     29 5.38e-01  139 2.70e+00 100
SNESSetUp              1 1.0 1.3041e-05 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
SNESFunctionEval       1 1.0 1.8054e-01 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   2  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
SNESJacobianEval       3 1.0 2.6576e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
DMCoarsen              2 1.0 2.7068e+00 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00 16  0  0  0  0  24  0  0  0  0     0       0     10 9.39e-02   16 1.54e-01  0
DMCreateInterp         2 1.0 5.3285e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
DMCreateInject         2 1.0 2.5751e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
DMCreateMat            2 1.0 1.0030e-02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      4 3.40e-02    4 3.40e-02  0
CreateFunctionSpace       9 1.0 2.9507e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ParLoopExecute       612 1.0 7.3172e+00 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00 44  0  0  0  0  64  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ParLoop_wrap_expression_kernel       4 1.0 1.4362e-01 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ApplyBC                3 1.0 1.2919e-01 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ParLoop_wrap_expression       6 1.0 2.1715e-01 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   2  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ParLoop_wrap_zero     362 1.0 2.2857e-01 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   2  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ParLoop_wrap_form0_cell_integral_otherwise     113 1.0 2.7782e-01 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ParLoop_wrap_loopy_kernel_inject       6 1.0 2.1464e+00 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00 13  0  0  0  0  19  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ParLoop_wrap_loopy_kernel_restrict       7 1.0 2.2218e+00 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00 13  0  0  0  0  19  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ParLoop_wrap_copy     109 1.0 1.1656e-01 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ParLoop_wrap_loopy_kernel_prolong       5 1.0 1.9487e+00 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00 12  0  0  0  0  17  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0

--- Event Stage 2: benchmark

VecMDot               95 1.0 9.1221e-03 1.0 1.77e+06 1.0 0.0e+00 0.0e+00 0.0e+00  0 13  0  0  0   0 26  0  0  0   194    1440      0 0.00e+00    0 0.00e+00 100
VecNorm              101 1.0 7.2613e-03 1.0 2.63e+05 1.0 0.0e+00 0.0e+00 0.0e+00  0  2  0  0  0   0  4  0  0  0    36      37      0 0.00e+00    0 0.00e+00 100
VecScale             100 1.0 1.0330e-03 1.0 1.25e+05 1.0 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  2  0  0  0   121     136      0 0.00e+00    0 0.00e+00 100
VecCopy              373 1.0 6.4755e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
VecSet               170 1.0 2.1270e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
VecAXPY                9 1.0 9.3518e-05 1.0 5.21e+04 1.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  1  0  0  0   557     667      0 0.00e+00    0 0.00e+00 100
VecAYPX               20 1.0 1.3418e-03 1.0 1.36e+05 1.0 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  2  0  0  0   101     104      0 0.00e+00    0 0.00e+00 100
VecAXPBYCZ             6 1.0 1.5960e-04 1.0 1.98e+05 1.0 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  3  0  0  0  1244    1466      0 0.00e+00    0 0.00e+00 100
VecMAXPY             100 1.0 1.0155e-02 1.0 4.00e+06 1.0 0.0e+00 0.0e+00 0.0e+00  0 30  0  0  0   0 60  0  0  0   393     452      0 0.00e+00    0 0.00e+00 100
VecPointwiseMult     112 1.0 1.7507e-03 1.0 1.65e+05 1.0 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  2  0  0  0    94     113      5 1.35e-01    0 0.00e+00 100
VecNormalize         100 1.0 8.3345e-03 1.0 3.75e+05 1.0 0.0e+00 0.0e+00 0.0e+00  0  3  0  0  0   0  6  0  0  0    45      47      0 0.00e+00    0 0.00e+00 100
VecCUDACopyTo         35 1.0 4.5879e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0     35 8.27e-01    0 0.00e+00  0
VecCUDACopyFrom      149 1.0 1.6094e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00  149 3.17e+00  0
MatMult              111 1.0 5.0005e-01 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  3  0  0  0  0  13  0  0  0  0     0       0      0 0.00e+00    3 6.95e-02  0
MatMultAdd             3 1.0 1.2900e-03 1.0 1.98e+04 1.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0    15     325      0 0.00e+00    0 0.00e+00 100
MatMultTranspose       9 1.0 2.8882e+00 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00 18  0  0  0  0  73  0  0  0  0     0       0      3 1.22e-01    6 2.93e-01  0
MatResidual            3 1.0 9.9705e-04 1.0 1.98e+04 1.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0    20     156      0 0.00e+00    0 0.00e+00 100
MatAssemblyBegin       6 1.0 8.2170e-06 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
MatAssemblyEnd         6 1.0 7.7370e-06 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
PCSetUp                1 1.0 1.3400e+00 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  8  0  0  0  0  34  0  0  0  0     0       0     21 3.33e-01   65 1.26e+00  0
PCApply                1 1.0 2.5951e+00 1.0 6.67e+06 1.0 0.0e+00 0.0e+00 0.0e+00 16 50  0  0  0  65100  0  0  0     3     244      8 2.05e-01   74 1.44e+00 100
KSPSetUp               6 1.0 2.0415e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00   23 6.50e-01  0
KSPSolve               1 1.0 3.9352e+00 1.0 6.69e+06 1.0 0.0e+00 0.0e+00 0.0e+00 24 50  0  0  0  99100  0  0  0     2     234     29 5.38e-01  139 2.70e+00 100
KSPGMRESOrthog        95 1.0 2.0663e-02 1.0 5.30e+06 1.0 0.0e+00 0.0e+00 0.0e+00  0 40  0  0  0   1 79  0  0  0   256     564      0 0.00e+00    0 0.00e+00 100
SNESSolve              1 1.0 3.9411e+00 1.0 6.70e+06 1.0 0.0e+00 0.0e+00 0.0e+00 24 50  0  0  0  99100  0  0  0     2     234     29 5.38e-01  139 2.70e+00 100
SNESSetUp              1 1.0 8.1500e-06 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
SNESFunctionEval       1 1.0 5.7662e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
SNESJacobianEval       3 1.0 1.6516e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
DMCoarsen              2 1.0 4.6704e-01 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  3  0  0  0  0  12  0  0  0  0     0       0     10 9.39e-02   16 1.54e-01  0
DMCreateInterp         2 1.0 3.2084e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
DMCreateInject         2 1.0 3.2294e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
DMCreateMat            2 1.0 9.0365e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      4 3.40e-02    4 3.40e-02  0
CreateFunctionSpace       9 1.0 2.0716e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ParLoopExecute       612 1.0 2.3308e-02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   1  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ParLoop_wrap_expression_kernel       4 1.0 1.0896e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ApplyBC                3 1.0 1.4016e-02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ParLoop_wrap_expression       6 1.0 1.3943e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ParLoop_wrap_zero     362 1.0 5.1832e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ParLoop_wrap_form0_cell_integral_otherwise     113 1.0 1.5781e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ParLoop_wrap_loopy_kernel_inject       6 1.0 1.2673e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ParLoop_wrap_loopy_kernel_restrict       7 1.0 3.0819e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ParLoop_wrap_copy     109 1.0 1.7387e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ParLoop_wrap_loopy_kernel_prolong       5 1.0 9.7893e-05 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
---------------------------------------------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

           Container     8              5         2920     0.
              Viewer     1              0            0     0.
           Index Set   256            207       315600     0.
             Section    76             52        38272     0.
   Star Forest Graph    60             49        49472     0.
              Vector    16             53      1302888     0.
              Matrix     8              8        22848     0.
     DMKSP interface     0              3         1992     0.
              DMSNES     0              3         2040     0.
    Distributed Mesh    34             26       115744     0.
            DM Label    90             50        32000     0.
    GraphPartitioner     8              5         3440     0.
     Discrete System    38             30        28080     0.

--- Event Stage 1: warmup

           Index Set    11              6         5424     0.
             Section     2              0            0     0.
   Star Forest Graph    10              5         4960     0.
              Vector   141             97      2146056     0.
              Matrix     7              4        11424     0.
      Preconditioner     4              4         4304     0.
       Krylov Solver     6              6        84056     0.
     DMKSP interface     5              2         1328     0.
                SNES     1              1         1412     0.
              DMSNES     3              0            0     0.
    Distributed Mesh     5              0            0     0.
     Discrete System     5              0            0     0.

--- Event Stage 2: benchmark

           Index Set    11              6         5424     0.
             Section     2              0            0     0.
   Star Forest Graph    10              5         4960     0.
              Vector   141            106      2329808     0.
              Matrix     7              7        19992     0.
      Preconditioner     4              4         4304     0.
       Krylov Solver     6              6        84056     0.
     DMKSP interface     5              2         1328     0.
                SNES     1              1         1412     0.
              DMSNES     3              0            0     0.
    Distributed Mesh     5              0            0     0.
     Discrete System     5              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.64e-08
#PETSc Option Table entries:
-log_view
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --download-eigen=/home/clara/thesis/packages/eigen-3.3.3.tgz --with-fortran-bindings=0 --download-chaco --download-metis --download-parmetis --download-scalapack --download-hypre --download-mumps --download-netcdf --with-hdf5=1 --download-hdf5=https://support.hdfgroup.org/ftp/HDF5/releases/hdf5-1.10/hdf5-1.10.6/src/hdf5-1.10.6.tar.bz2 --download-fblaslapack --with-cuda=1 --with-cuda-dir=/usr/local/cuda-10.2 --download-zlib --with-cudac=nvcc --mpicc=/opt/openmpi-4.0.3/bin/mpicc --mpicxx=/opt/openmpi-4.0.3/bin/mpicxx --mpif90=/opt/openmpi-4.0.3/bin/mpif90 --mpiexec=/opt/openmpi-4.0.3/bin/mpiexec --with-mpi-dir=/opt/openmpi-4.0.3/
-----------------------------------------
Libraries compiled on 2020-04-29 22:25:09 on clara 
Machine characteristics: Linux-5.3.0-46-generic-x86_64-with-Ubuntu-18.04-bionic
Using PETSc directory: /home/clara/thesis/freshGPU/packages/petsc_cuda
Using PETSc arch: arch-linux2-c-debug
-----------------------------------------

Using C compiler: /opt/openmpi-4.0.3/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -g3  
Using Fortran compiler: /opt/openmpi-4.0.3/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -g    
-----------------------------------------

Using include paths: -I/home/clara/thesis/freshGPU/packages/petsc_cuda/include -I/home/clara/thesis/freshGPU/packages/petsc_cuda/arch-linux2-c-debug/include -I/home/clara/thesis/freshGPU/packages/petsc_cuda/arch-linux2-c-debug/include/eigen3 -I/usr/local/cuda-10.2/include -I/opt/openmpi-4.0.3/include
-----------------------------------------

Using C linker: /opt/openmpi-4.0.3/bin/mpicc
Using Fortran linker: /opt/openmpi-4.0.3/bin/mpif90
Using libraries: -Wl,-rpath,/home/clara/thesis/freshGPU/packages/petsc_cuda/arch-linux2-c-debug/lib -L/home/clara/thesis/freshGPU/packages/petsc_cuda/arch-linux2-c-debug/lib -lpetsc -Wl,-rpath,/home/clara/thesis/freshGPU/packages/petsc_cuda/arch-linux2-c-debug/lib -L/home/clara/thesis/freshGPU/packages/petsc_cuda/arch-linux2-c-debug/lib -Wl,-rpath,/usr/local/cuda-10.2/lib64 -L/usr/local/cuda-10.2/lib64 -Wl,-rpath,/opt/openmpi-4.0.3/lib -L/opt/openmpi-4.0.3/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/7 -L/usr/lib/gcc/x86_64-linux-gnu/7 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lflapack -lfblas -lX11 -lnetcdf -lhdf5hl_fortran -lhdf5_fortran -lhdf5_hl -lhdf5 -lchaco -lparmetis -lmetis -lm -lz -lcufft -lcublas -lcudart -lcusparse -lcusolver -lcuda -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lquadmath -lstdc++ -ldl
-----------------------------------------



      ##########################################################
      #                                                        #
      #                       WARNING!!!                       #
      #                                                        #
      #   This code was compiled with a debugging option.      #
      #   To get timing results run ./configure                #
      #   using --with-debugging=no, the performance will      #
      #   be generally two or three times faster.              #
      #                                                        #
      ##########################################################


