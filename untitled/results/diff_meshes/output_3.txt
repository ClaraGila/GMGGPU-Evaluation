1.0919370460198432e-07
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------



      ##########################################################
      #                                                        #
      #                       WARNING!!!                       #
      #                                                        #
      #   This code was compiled with a debugging option.      #
      #   To get timing results run ./configure                #
      #   using --with-debugging=no, the performance will      #
      #   be generally two or three times faster.              #
      #                                                        #
      ##########################################################


/home/clara/PycharmProjects/untitled/diff_meshes.py on a arch-linux2-c-debug named clara with 1 processor, by clara Mon May 18 11:17:52 2020
Using Petsc Development GIT revision: v3.4.2-29593-g905158c6f9  GIT Date: 2020-04-24 15:50:17 +0100

                         Max       Max/Min     Avg       Total 
Time (sec):           1.866e+01     1.000   1.866e+01
Objects:              1.309e+03     1.000   1.309e+03
Flop:                 3.972e+07     1.000   3.972e+07  3.972e+07
Flop/sec:             2.129e+06     1.000   2.129e+06  2.129e+06
Memory:               7.767e+06     1.000   7.767e+06  7.767e+06
MPI Messages:         0.000e+00     0.000   0.000e+00  0.000e+00
MPI Message Lengths:  0.000e+00     0.000   0.000e+00  0.000e+00
MPI Reductions:       0.000e+00     0.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total 
 0:      Main Stage: 1.5786e+00   8.5%  0.0000e+00   0.0%  0.000e+00   0.0%  0.000e+00        0.0%  0.000e+00   0.0% 
 1:          warmup: 9.8552e+00  52.8%  1.9861e+07  50.0%  0.000e+00   0.0%  0.000e+00        0.0%  0.000e+00   0.0% 
 2:       benchmark: 7.2268e+00  38.7%  1.9861e+07  50.0%  0.000e+00   0.0%  0.000e+00        0.0%  0.000e+00   0.0% 

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
   GPU Mflop/s: 10e-6 * (sum of flop on GPU over all processors)/(max GPU time over all processors)
   CpuToGpu Count: total number of CPU to GPU copies per processor
   CpuToGpu Size (Mbytes): 10e-6 * (total size of CPU to GPU copies per processor)
   GpuToCpu Count: total number of GPU to CPU copies per processor
   GpuToCpu Size (Mbytes): 10e-6 * (total size of GPU to CPU copies per processor)
   GPU %F: percent flops on GPU in this event
------------------------------------------------------------------------------------------------------------------------


      ##########################################################
      #                                                        #
      #                       WARNING!!!                       #
      #                                                        #
      #   This code was compiled with a debugging option.      #
      #   To get timing results run ./configure                #
      #   using --with-debugging=no, the performance will      #
      #   be generally two or three times faster.              #
      #                                                        #
      ##########################################################


Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total   GPU    - CpuToGpu -   - GpuToCpu - GPU
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s Mflop/s Count   Size   Count   Size  %F
---------------------------------------------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

PetscBarrier           6 1.0 2.2956e-01 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0  15  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
SFSetGraph             2 1.0 2.5270e-06 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
VecSet                22 1.0 4.7805e-05 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
VecCUDACopyTo          2 1.0 5.8694e-05 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      2 3.12e-01    0 0.00e+00  0
VecCUDACopyFrom        4 1.0 1.0505e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    4 6.25e-01  0
DMPlexCrFrCeLi         2 1.0 4.7109e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
DMPlexCrFrCeLiCo       2 1.0 1.1300e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
DMPlexInterp           2 1.0 3.5912e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
DMPlexStratify        10 1.0 1.6630e-02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   1  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
DMPlexSymmetrize      10 1.0 1.6678e-02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   1  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
CreateMesh            32 1.0 2.1014e-01 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0  13  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
Mesh: reorder          8 1.0 2.7192e-02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   2  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
Mesh: numbering        8 1.0 1.1773e-01 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   7  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
CreateFunctionSpace      10 1.0 1.2281e-01 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   8  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ParLoopExecute         3 1.0 5.3864e-02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   3  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ParLoop_wrap_expression_kernel       2 1.0 2.3139e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ParLoop_wrap_expression       2 1.0 3.1902e-05 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
AssembleExpression       1 1.0 9.3195e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   1  0  0  0  0     0       0      0 0.00e+00    1 2.07e-01  0
ParLoop_wrap_form_cell_integral_otherwise       2 1.0 1.1996e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ParLoopRednBegin       1 1.0 2.1729e-05 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ParLoopRednEnd         1 1.0 1.7508e-05 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0

--- Event Stage 1: warmup

VecMDot              130 1.0 1.0997e-02 1.0 4.90e+06 1.0 0.0e+00 0.0e+00 0.0e+00  0 12  0  0  0   0 25  0  0  0   446    2891      0 0.00e+00    0 0.00e+00 100
VecNorm              138 1.0 1.1275e-02 1.0 8.95e+05 1.0 0.0e+00 0.0e+00 0.0e+00  0  2  0  0  0   0  5  0  0  0    79      81      0 0.00e+00    0 0.00e+00 100
VecScale             137 1.0 1.9603e-03 1.0 4.22e+05 1.0 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  2  0  0  0   215     233      0 0.00e+00    0 0.00e+00 100
VecCopy              546 1.0 1.2448e-02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
VecSet               227 1.0 4.9832e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
VecAXPY               14 1.0 2.7416e-04 1.0 2.12e+05 1.0 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0   773     863      0 0.00e+00    0 0.00e+00 100
VecAYPX               39 1.0 6.6528e-04 1.0 5.97e+05 1.0 0.0e+00 0.0e+00 0.0e+00  0  2  0  0  0   0  3  0  0  0   898     997      0 0.00e+00    0 0.00e+00 100
VecAXPBYCZ            12 1.0 3.3336e-04 1.0 8.82e+05 1.0 0.0e+00 0.0e+00 0.0e+00  0  2  0  0  0   0  4  0  0  0  2645    3120      0 0.00e+00    0 0.00e+00 100
VecMAXPY             137 1.0 1.5021e-02 1.0 1.14e+07 1.0 0.0e+00 0.0e+00 0.0e+00  0 29  0  0  0   0 57  0  0  0   756     861      0 0.00e+00    0 0.00e+00 100
VecPointwiseMult     161 1.0 2.8136e-03 1.0 5.98e+05 1.0 0.0e+00 0.0e+00 0.0e+00  0  2  0  0  0   0  3  0  0  0   213     261      7 5.50e-01    0 0.00e+00 100
VecNormalize         137 1.0 1.3361e-02 1.0 1.26e+06 1.0 0.0e+00 0.0e+00 0.0e+00  0  3  0  0  0   0  6  0  0  0    95      99      0 0.00e+00    0 0.00e+00 100
VecCUDACopyTo         48 1.0 1.6949e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0     48 3.32e+00    0 0.00e+00  0
VecCUDACopyFrom      196 1.0 2.8565e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00  196 1.25e+01  0
MatMult              160 1.0 9.0153e-01 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  5  0  0  0  0   9  0  0  0  0     0       0      0 0.00e+00    4 2.77e-01  0
MatMultAdd             6 1.0 2.7307e-03 1.0 8.82e+04 1.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0    32     368      0 0.00e+00    0 0.00e+00 100
MatMultTranspose      15 1.0 7.3729e+00 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00 40  0  0  0  0  75  0  0  0  0     0       0      4 4.84e-01    8 1.17e+00  0
MatResidual            6 1.0 2.4582e-03 1.0 8.82e+04 1.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0    36     120      0 0.00e+00    0 0.00e+00 100
MatAssemblyBegin       8 1.0 1.3089e-05 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
MatAssemblyEnd         8 1.0 1.4185e-05 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
PCSetUp                1 1.0 4.5023e+00 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00 24  0  0  0  0  46  0  0  0  0     0       0     31 1.35e+00   92 5.05e+00  0
PCApply                1 1.0 4.8944e+00 1.0 1.98e+07 1.0 0.0e+00 0.0e+00 0.0e+00 26 50  0  0  0  50 99  0  0  0     4     444     11 8.27e-01   94 5.59e+00 100
KSPSetUp               8 1.0 3.3391e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00   31 2.62e+00  0
KSPSolve               1 1.0 9.3969e+00 1.0 1.98e+07 1.0 0.0e+00 0.0e+00 0.0e+00 50 50  0  0  0  95100  0  0  0     2     427     42 2.18e+00  186 1.06e+01 100
KSPGMRESOrthog       130 1.0 2.7800e-02 1.0 1.47e+07 1.0 0.0e+00 0.0e+00 0.0e+00  0 37  0  0  0   0 74  0  0  0   529    1057      0 0.00e+00    0 0.00e+00 100
SNESSolve              1 1.0 9.5703e+00 1.0 1.99e+07 1.0 0.0e+00 0.0e+00 0.0e+00 51 50  0  0  0  97100  0  0  0     2     427     42 2.18e+00  186 1.06e+01 100
SNESSetUp              1 1.0 1.6389e-05 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
SNESFunctionEval       1 1.0 1.7315e-01 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   2  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
SNESJacobianEval       4 1.0 3.2489e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
DMCoarsen              3 1.0 7.7092e-01 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  4  0  0  0  0   8  0  0  0  0     0       0     15 3.83e-01   24 6.27e-01  0
DMCreateInterp         3 1.0 4.7044e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
DMCreateInject         3 1.0 3.6097e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
DMCreateMat            3 1.0 1.4417e-02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      6 1.39e-01    6 1.39e-01  0
CreateFunctionSpace      13 1.0 4.5929e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ParLoopExecute       890 1.0 3.4577e+00 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00 19  0  0  0  0  35  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ParLoop_wrap_expression_kernel       5 1.0 1.4344e-01 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ApplyBC                4 1.0 1.3713e-01 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ParLoop_wrap_expression       8 1.0 2.2370e-01 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   2  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ParLoop_wrap_zero     528 1.0 2.3118e-01 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   2  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ParLoop_wrap_form0_cell_integral_otherwise     162 1.0 2.8191e-01 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   3  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ParLoop_wrap_loopy_kernel_inject       9 1.0 1.6859e-01 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   2  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ParLoop_wrap_loopy_kernel_restrict      12 1.0 2.1416e+00 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00 11  0  0  0  0  22  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ParLoop_wrap_copy     157 1.0 1.1337e-01 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ParLoop_wrap_loopy_kernel_prolong       9 1.0 1.3129e-01 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0

--- Event Stage 2: benchmark

VecMDot              130 1.0 1.2862e-02 1.0 4.90e+06 1.0 0.0e+00 0.0e+00 0.0e+00  0 12  0  0  0   0 25  0  0  0   381    1839      0 0.00e+00    0 0.00e+00 100
VecNorm              138 1.0 9.2591e-03 1.0 8.95e+05 1.0 0.0e+00 0.0e+00 0.0e+00  0  2  0  0  0   0  5  0  0  0    97      99      0 0.00e+00    0 0.00e+00 100
VecScale             137 1.0 1.3661e-03 1.0 4.22e+05 1.0 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  2  0  0  0   309     353      0 0.00e+00    0 0.00e+00 100
VecCopy              546 1.0 1.3392e-02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
VecSet               227 1.0 7.4703e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
VecAXPY               14 1.0 2.7602e-04 1.0 2.12e+05 1.0 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0   768     860      0 0.00e+00    0 0.00e+00 100
VecAYPX               39 1.0 1.9347e-03 1.0 5.97e+05 1.0 0.0e+00 0.0e+00 0.0e+00  0  2  0  0  0   0  3  0  0  0   309     324      0 0.00e+00    0 0.00e+00 100
VecAXPBYCZ            12 1.0 3.4507e-04 1.0 8.82e+05 1.0 0.0e+00 0.0e+00 0.0e+00  0  2  0  0  0   0  4  0  0  0  2555    3057      0 0.00e+00    0 0.00e+00 100
VecMAXPY             137 1.0 1.3728e-02 1.0 1.14e+07 1.0 0.0e+00 0.0e+00 0.0e+00  0 29  0  0  0   0 57  0  0  0   827     972      0 0.00e+00    0 0.00e+00 100
VecPointwiseMult     161 1.0 4.3226e-03 1.0 5.98e+05 1.0 0.0e+00 0.0e+00 0.0e+00  0  2  0  0  0   0  3  0  0  0   138     168      7 5.50e-01    0 0.00e+00 100
VecNormalize         137 1.0 1.0728e-02 1.0 1.26e+06 1.0 0.0e+00 0.0e+00 0.0e+00  0  3  0  0  0   0  6  0  0  0   118     124      0 0.00e+00    0 0.00e+00 100
VecCUDACopyTo         48 1.0 2.5826e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0     48 3.32e+00    0 0.00e+00  0
VecCUDACopyFrom      196 1.0 2.8677e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00  196 1.25e+01  0
MatMult              160 1.0 8.8262e-01 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  5  0  0  0  0  12  0  0  0  0     0       0      0 0.00e+00    4 2.77e-01  0
MatMultAdd             6 1.0 2.7762e-03 1.0 8.82e+04 1.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0    32     365      0 0.00e+00    0 0.00e+00 100
MatMultTranspose      15 1.0 5.6484e+00 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00 30  0  0  0  0  78  0  0  0  0     0       0      4 4.84e-01    8 1.17e+00  0
MatResidual            6 1.0 2.4351e-03 1.0 8.82e+04 1.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0    36     245      0 0.00e+00    0 0.00e+00 100
MatAssemblyBegin       8 1.0 1.0895e-05 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
MatAssemblyEnd         8 1.0 1.0914e-05 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
PCSetUp                1 1.0 1.9985e+00 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00 11  0  0  0  0  28  0  0  0  0     0       0     31 1.35e+00   92 5.05e+00  0
PCApply                1 1.0 5.1718e+00 1.0 1.98e+07 1.0 0.0e+00 0.0e+00 0.0e+00 28 50  0  0  0  72 99  0  0  0     4     443     11 8.27e-01   94 5.59e+00 100
KSPSetUp               8 1.0 4.0474e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00   31 2.62e+00  0
KSPSolve               1 1.0 7.1704e+00 1.0 1.98e+07 1.0 0.0e+00 0.0e+00 0.0e+00 38 50  0  0  0  99100  0  0  0     3     400     42 2.18e+00  186 1.06e+01 100
KSPGMRESOrthog       130 1.0 2.8733e-02 1.0 1.47e+07 1.0 0.0e+00 0.0e+00 0.0e+00  0 37  0  0  0   0 74  0  0  0   512    1099      0 0.00e+00    0 0.00e+00 100
SNESSolve              1 1.0 7.1762e+00 1.0 1.99e+07 1.0 0.0e+00 0.0e+00 0.0e+00 38 50  0  0  0  99100  0  0  0     3     401     42 2.18e+00  186 1.06e+01 100
SNESSetUp              1 1.0 9.0020e-06 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
SNESFunctionEval       1 1.0 5.6542e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
SNESJacobianEval       4 1.0 4.4522e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
DMCoarsen              3 1.0 5.1172e-01 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  3  0  0  0  0   7  0  0  0  0     0       0     15 3.83e-01   24 6.27e-01  0
DMCreateInterp         3 1.0 4.3346e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
DMCreateInject         3 1.0 3.8148e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
DMCreateMat            3 1.0 1.5534e-02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      6 1.39e-01    6 1.39e-01  0
CreateFunctionSpace      13 1.0 3.9257e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ParLoopExecute       890 1.0 3.8526e-02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   1  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ParLoop_wrap_expression_kernel       5 1.0 1.4984e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ApplyBC                4 1.0 1.9810e-02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ParLoop_wrap_expression       8 1.0 2.3158e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ParLoop_wrap_zero     528 1.0 8.5995e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ParLoop_wrap_form0_cell_integral_otherwise     162 1.0 2.5182e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ParLoop_wrap_loopy_kernel_inject       9 1.0 1.9943e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ParLoop_wrap_loopy_kernel_restrict      12 1.0 5.7529e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ParLoop_wrap_copy     157 1.0 2.8023e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
ParLoop_wrap_loopy_kernel_prolong       9 1.0 1.8826e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
---------------------------------------------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

           Container    10              2         1168     0.
              Viewer     1              0            0     0.
           Index Set   342            192       451064     0.
             Section    98             30        22080     0.
   Star Forest Graph    76             34        33728     0.
              Vector    20             15       713064     0.
              Matrix    10              6        17136     0.
    Distributed Mesh    44             10        25088     0.
            DM Label   118             10         6400     0.
    GraphPartitioner    10              2         1376     0.
     Discrete System    48             14        13104     0.

--- Event Stage 1: warmup

           Index Set    15              8         7232     0.
             Section     3              0            0     0.
   Star Forest Graph    14              7         6944     0.
              Vector   185            125      7997160     0.
              Matrix    10              6        17136     0.
      Preconditioner     5              5         5328     0.
       Krylov Solver     8              8       116056     0.
     DMKSP interface     7              3         1992     0.
                SNES     1              1         1412     0.
              DMSNES     4              0            0     0.
    Distributed Mesh     7              0            0     0.
     Discrete System     7              0            0     0.

--- Event Stage 2: benchmark

           Container     0              4         2336     0.
           Index Set    15             90       303216     0.
             Section     3             37        27232     0.
   Star Forest Graph    14             35        35872     0.
              Vector   185            194     12961096     0.
              Matrix    10             14        39984     0.
      Preconditioner     5              5         5328     0.
       Krylov Solver     8              8       116056     0.
     DMKSP interface     7              7         4648     0.
                SNES     1              1         1412     0.
              DMSNES     4              4         2720     0.
    Distributed Mesh     7             24       122688     0.
            DM Label     0             54        34560     0.
    GraphPartitioner     0              4         2752     0.
     Discrete System     7             24        22464     0.
========================================================================================================================
Average time to get PetscTime(): 2.7e-08
#PETSc Option Table entries:
-log_view
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --download-eigen=/home/clara/thesis/packages/eigen-3.3.3.tgz --with-fortran-bindings=0 --download-chaco --download-metis --download-parmetis --download-scalapack --download-hypre --download-mumps --download-netcdf --with-hdf5=1 --download-hdf5=https://support.hdfgroup.org/ftp/HDF5/releases/hdf5-1.10/hdf5-1.10.6/src/hdf5-1.10.6.tar.bz2 --download-fblaslapack --with-cuda=1 --with-cuda-dir=/usr/local/cuda-10.2 --download-zlib --with-cudac=nvcc --mpicc=/opt/openmpi-4.0.3/bin/mpicc --mpicxx=/opt/openmpi-4.0.3/bin/mpicxx --mpif90=/opt/openmpi-4.0.3/bin/mpif90 --mpiexec=/opt/openmpi-4.0.3/bin/mpiexec --with-mpi-dir=/opt/openmpi-4.0.3/
-----------------------------------------
Libraries compiled on 2020-04-29 22:25:09 on clara 
Machine characteristics: Linux-5.3.0-46-generic-x86_64-with-Ubuntu-18.04-bionic
Using PETSc directory: /home/clara/thesis/freshGPU/packages/petsc_cuda
Using PETSc arch: arch-linux2-c-debug
-----------------------------------------

Using C compiler: /opt/openmpi-4.0.3/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -g3  
Using Fortran compiler: /opt/openmpi-4.0.3/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -g    
-----------------------------------------

Using include paths: -I/home/clara/thesis/freshGPU/packages/petsc_cuda/include -I/home/clara/thesis/freshGPU/packages/petsc_cuda/arch-linux2-c-debug/include -I/home/clara/thesis/freshGPU/packages/petsc_cuda/arch-linux2-c-debug/include/eigen3 -I/usr/local/cuda-10.2/include -I/opt/openmpi-4.0.3/include
-----------------------------------------

Using C linker: /opt/openmpi-4.0.3/bin/mpicc
Using Fortran linker: /opt/openmpi-4.0.3/bin/mpif90
Using libraries: -Wl,-rpath,/home/clara/thesis/freshGPU/packages/petsc_cuda/arch-linux2-c-debug/lib -L/home/clara/thesis/freshGPU/packages/petsc_cuda/arch-linux2-c-debug/lib -lpetsc -Wl,-rpath,/home/clara/thesis/freshGPU/packages/petsc_cuda/arch-linux2-c-debug/lib -L/home/clara/thesis/freshGPU/packages/petsc_cuda/arch-linux2-c-debug/lib -Wl,-rpath,/usr/local/cuda-10.2/lib64 -L/usr/local/cuda-10.2/lib64 -Wl,-rpath,/opt/openmpi-4.0.3/lib -L/opt/openmpi-4.0.3/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/7 -L/usr/lib/gcc/x86_64-linux-gnu/7 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lflapack -lfblas -lX11 -lnetcdf -lhdf5hl_fortran -lhdf5_fortran -lhdf5_hl -lhdf5 -lchaco -lparmetis -lmetis -lm -lz -lcufft -lcublas -lcudart -lcusparse -lcusolver -lcuda -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lquadmath -lstdc++ -ldl
-----------------------------------------



      ##########################################################
      #                                                        #
      #                       WARNING!!!                       #
      #                                                        #
      #   This code was compiled with a debugging option.      #
      #   To get timing results run ./configure                #
      #   using --with-debugging=no, the performance will      #
      #   be generally two or three times faster.              #
      #                                                        #
      ##########################################################


